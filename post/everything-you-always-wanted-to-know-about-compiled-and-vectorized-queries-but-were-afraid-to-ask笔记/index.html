<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>《Everything You Always Wanted to Know About Compiled and Vectorized Queries But Were Afraid to Ask》笔记 - 后端技术小屋</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=author content="后端侠"><meta name=description content="1 引言 大部分现代查询引擎使用向量化和代码生成其中一种。 使用向量化的系统: VectorWise，DB2 BLU, columnar SQL Server, Quickstep 使用代码生成的系统：Hyper"><meta name=keywords content="Hugo,theme,后端侠"><meta name=generator content="Hugo 0.62.2 with theme even"><link rel=canonical href=https://backendhouse.github.io/post/everything-you-always-wanted-to-know-about-compiled-and-vectorized-queries-but-were-afraid-to-ask%E7%AC%94%E8%AE%B0/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/manifest.json><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link href=/sass/main.min.a2095472a2a8d7ddda1334cf60051cbe40ed55f2467554bb6aa4c17c9bcd27a4.css rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin=anonymous><meta property="og:title" content="《Everything You Always Wanted to Know About Compiled and Vectorized Queries But Were Afraid to Ask》笔记"><meta property="og:description" content="1 引言 大部分现代查询引擎使用向量化和代码生成其中一种。 使用向量化的系统: VectorWise，DB2 BLU, columnar SQL Server, Quickstep 使用代码生成的系统：Hyper"><meta property="og:type" content="article"><meta property="og:url" content="https://backendhouse.github.io/post/everything-you-always-wanted-to-know-about-compiled-and-vectorized-queries-but-were-afraid-to-ask%E7%AC%94%E8%AE%B0/"><meta property="article:published_time" content="2025-05-20T14:23:08+08:00"><meta property="article:modified_time" content="2025-05-20T14:23:08+08:00"><meta itemprop=name content="《Everything You Always Wanted to Know About Compiled and Vectorized Queries But Were Afraid to Ask》笔记"><meta itemprop=description content="1 引言 大部分现代查询引擎使用向量化和代码生成其中一种。 使用向量化的系统: VectorWise，DB2 BLU, columnar SQL Server, Quickstep 使用代码生成的系统：Hyper"><meta itemprop=datePublished content="2025-05-20T14:23:08+08:00"><meta itemprop=dateModified content="2025-05-20T14:23:08+08:00"><meta itemprop=wordCount content="3550"><meta itemprop=keywords content="paper,"><meta name=twitter:card content="summary"><meta name=twitter:title content="《Everything You Always Wanted to Know About Compiled and Vectorized Queries But Were Afraid to Ask》笔记"><meta name=twitter:description content="1 引言 大部分现代查询引擎使用向量化和代码生成其中一种。 使用向量化的系统: VectorWise，DB2 BLU, columnar SQL Server, Quickstep 使用代码生成的系统：Hyper"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>后端技术小屋</a></div><div class=mobile-navbar-icon><span></span><span></span><span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=/><li class=mobile-menu-item>Home</li></a><a href=/post/><li class=mobile-menu-item>Archives</li></a><a href=/tags/><li class=mobile-menu-item>Tags</li></a><a href=/categories/><li class=mobile-menu-item>Categories</li></a><a href=/about/><li class=mobile-menu-item>About</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=/ class=logo>后端技术小屋</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/>Home</a></li><li class=menu-item><a class=menu-item-link href=/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=/tags/>Tags</a></li><li class=menu-item><a class=menu-item-link href=/categories/>Categories</a></li><li class=menu-item><a class=menu-item-link href=/about/>About</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>《Everything You Always Wanted to Know About Compiled and Vectorized Queries But Were Afraid to Ask》笔记</h1><div class=post-meta><span class=post-time>2025-05-20</span><div class=post-category><a href=/categories/paper/>paper</a></div></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class="post-toc-content always-active"><nav id=TableOfContents><ul><li><a href=#1-引言>1 引言</a></li><li><a href=#2-向量化-vs-代码生成>2 向量化 vs. 代码生成</a><ul><li><a href=#21-向量化算法>2.1 向量化算法</a></li><li><a href=#22-向量化hash-join和group-by>2.2 向量化hash join和group by</a></li></ul></li><li><a href=#3-实验方法>3 实验方法</a><ul><li><a href=#31--相关工作>3.1 相关工作</a></li><li><a href=#32-查询处理算法>3.2 查询处理算法</a></li><li><a href=#33-负载>3.3 负载</a></li></ul></li><li><a href=#4-微架构分析>4 微架构分析</a><ul><li><a href=#41-单线程性能>4.1 单线程性能</a></li><li><a href=#42-解释和指令缓存>4.2 解释和指令缓存</a></li><li><a href=#43-向量大小>4.3 向量大小</a></li></ul></li><li><a href=#5-数据并行执行simd>5 数据并行执行(SIMD)</a><ul><li><a href=#43-向量大小-1>4.3 向量大小</a></li></ul></li><li><a href=#5-数据并行执行simd-1>5 数据并行执行(SIMD)</a><ul><li><a href=#51-数据并行选择>5.1 数据并行选择</a></li><li><a href=#52-数据并行hash-table-probe>5.2 数据并行hash table probe</a></li><li><a href=#54-总结>5.4 总结</a></li></ul></li><li><a href=#6-查询内并行化>6 查询内并行化</a><ul><li><a href=#62-多线程执行>6.2 多线程执行</a></li></ul></li><li><a href=#8-总结>8 总结</a></li></ul></nav></div></div><div class=post-content><h1 id=1-引言>1 引言</h1><p>大部分现代查询引擎使用向量化和代码生成其中一种。</p><p>使用向量化的系统: VectorWise，DB2 BLU, columnar SQL Server, Quickstep
使用代码生成的系统：Hyper, Apache Spark, Peloton</p><p>为了公平的比较向量化和代码生成在OLAP场景中孰快孰慢，论文实现了两个用于测试的系统，分别基于向量化和代码生成，前者叫Tectorwise(TW), 后者叫Typer。实验结果表明，两种方法都能带来高效的执行引擎，并且性能差异通常不会很大。基于编译的引擎在计算密集型查询中具有优势，而矢量化引擎在隐藏cache-miss延迟方面表现更好，如group by, hash join中。</p><h1 id=2-向量化-vs-代码生成>2 向量化 vs. 代码生成</h1><p>向量化是pull-based的，每个算子都有next方法生成元组块，元祖块中包含多个元组，这摊销了迭代器调用开销。实际查询工作是由执行简单操作的原语组成，每种具体列类型都对应特定原语实现。通过摊销和类型特化，消除了传统引擎的大部分开销。</p><p>在代码生成中，每个算子实现了基于推送的接口，为给定查询生成代码。生成的代码针对查询的数据类型进行了特化，并将所有运算符融合成一个由非阻塞算子组成的流水线(可能嵌套)循环。然后可以将此生成的代码编译成高效的机器码。</p><h2 id=21-向量化算法>2.1 向量化算法</h2><p>以向量化风格实现的函数有两个约束</p><ul><li>仅工作在一个数据类型上</li><li>必须一次处理多个元祖
如下所示，(a)是常规风格的过滤实现，(b)是向量化风格的过滤实现。前者在一个循环中同时处理两个predicate, 后者每个predict各在一个循环中处理。这意味着如果predict数量有多个时，每个predict执行后都会出现临时的中间结果，最后对这些中间结果进行合并，得到最终的输出结果。</li></ul><p><img src=https://backendhouse.github.io/images/%E3%80%8AEverything%20You%20Always%20Wanted%20to%20Know%20About%20Compiled%20and%20Vectorized%20Queries%20But%20Were%20Afraid%20to%20Ask%E3%80%8B%E7%AC%94%E8%AE%B0/image.png alt="alt text"></p><h2 id=22-向量化hash-join和group-by>2.2 向量化hash join和group by</h2><p>hash join实现如下，probeHash批量计算输入向量的hash值，ht.findCandidates根据hash向量批量访问hash table, 输出匹配的candidates.</p><p><img src=https://backendhouse.github.io/images/%E3%80%8AEverything%20You%20Always%20Wanted%20to%20Know%20About%20Compiled%20and%20Vectorized%20Queries%20But%20Were%20Afraid%20to%20Ask%E3%80%8B%E7%AC%94%E8%AE%B0/image-1.png alt="alt text"></p><p>group by分成两个阶段，这两个阶段都会使用包含group by keys和聚合状态的哈希表。</p><h1 id=3-实验方法>3 实验方法</h1><p>在测试查询时，我们为向量化执行和编译执行使用相同的物理查询计划。我们不将查询解析、优化、代码生成和编译时间纳入我们的测量范围。Tectorwise 和 Typer 之间的唯一区别是查询执行方法:向量化与数据中心编译执行。</p><h2 id=31--相关工作>3.1 相关工作</h2><p>向量化: MonetDB/X100, VectorWise&mldr;
代码生成：Hyper, Peloton, Spark</p><h2 id=32-查询处理算法>3.2 查询处理算法</h2><p>论文实现了五种算子，scan, selection, project, join, aggregate。和生产级代码不同，论文实现不对算数表达式做overflow检查。scan本质上是一个for循环，用于扫描relatiion. selection被转化为if分支。投影通过将表达式转化为C代码实现。aggregate分为两阶段，有利于cache-friendly的并行化处理，第一阶段合并高频项并输出到每个分区，第二阶段聚合每个分区中的分组。</p><h2 id=33-负载>3.3 负载</h2><p>从TPC-H中选择5个代表性的查询, 数据集sf=1。这五个查询涵盖了 TPC‐H 最重要的性能挑战，任何在它们上表现良好的执行引擎很可能也会在TPC-H全部查询上高效。</p><p><img src=https://backendhouse.github.io/images/%E3%80%8AEverything%20You%20Always%20Wanted%20to%20Know%20About%20Compiled%20and%20Vectorized%20Queries%20But%20Were%20Afraid%20to%20Ask%E3%80%8B%E7%AC%94%E8%AE%B0/image-2.png alt="alt text"></p><h1 id=4-微架构分析>4 微架构分析</h1><h2 id=41-单线程性能>4.1 单线程性能</h2><p><img src=https://backendhouse.github.io/images/%E3%80%8AEverything%20You%20Always%20Wanted%20to%20Know%20About%20Compiled%20and%20Vectorized%20Queries%20But%20Were%20Afraid%20to%20Ask%E3%80%8B%E7%AC%94%E8%AE%B0/image-3.png alt="alt text"></p><p>现象：对于某些查询( Q1 、 Q18 )，Typer 更快，而对于其他查询( Q3 、 Q9 )，Tectorwise 更高效。相对性能范围从 Typer 快 74% ( Q1 )到 Tectorwise 快 32% ( Q9 ) 。</p><p><img src=https://backendhouse.github.io/images/%E3%80%8AEverything%20You%20Always%20Wanted%20to%20Know%20About%20Compiled%20and%20Vectorized%20Queries%20But%20Were%20Afraid%20to%20Ask%E3%80%8B%E7%AC%94%E8%AE%B0/image-4.png alt="alt text"></p><p>现象：Tectorwise 执行显著更多的指令(高达 2.4×)并且通常有更多的 L1 数据缓存未命中(高达 3.3×)。
解释：Tectorwise 将所有操作分解为简单步骤，并且必须在这些步 骤之间生成中间结果，这导致额外的指令和缓存访问；相比之下，Typer 通常可以将中间结果保存在 CPU 寄存器中， 因此可以用更少的指令执行相同的操作。
结论：Typer 对于可以 将中间结果保存在CPU 寄存器中且缓存未命中较少的计算查询更高效。</p><p>现象：对于 Q3 和 Q9，其性能由哈希表探测的效 率决定，Tectorwise 比 Typer 更快(分别快 4% 和 32% )。
解释：向量化在隐藏cache-miss时表现更好。Tectorwise的hash table probe只是一个简单循环，只执行probe, 因此cpu的乱序引擎可以推测的更远，并生成很多outstanding load. 而代码生成中循环更复杂，其中可能包含了scan, selection, hash table probe, aggregate的逻辑，cpu乱序窗口会更快被复杂循环填满，导致其发出的load相比向量化更少。此外复杂循环中branch-miss的代价更大。</p><p>综上，通过微架构分析，论文发现
向量化和代码生成性能相当，
Typer在计算密集型且cache-miss较少时更高效
TW在隐藏cache-miss上做的更好。</p><h2 id=42-解释和指令缓存>4.2 解释和指令缓存</h2><p>基于volcano风格的系统对每个处理的元组块执行昂贵的虚函数调用和类型分发。这就是向量化执行的解释开销，因为它不会对实际查询工作有贡献。DBMS中解释部分在1.5% (sf=10)。
那么向量化为什么比代码生成有更多指令呢？问题不在与向量化的解释开销（毕竟只占1.5%），而在于将原始结果物化到向量中的load/store指令。</p><h2 id=43-向量大小>4.3 向量大小</h2><p>batch size &lt; 64 or >64K时，性能显著下降。这是因为小向量不足以均摊解释开销，大向量无法放入CPU cache. 通常1k的尺寸对所有查询来说是一个很好的设置。</p><h1 id=5-数据并行执行simd>5 数据并行执行(SIMD)</h1><p>向量化引擎的基础是SIMD。AVX-512 SIMD指令集相比之前的AVX2或SSE4更强大，几乎所有操作都支持 掩码，并且增加了新指令，如压缩和扩展</p><h2 id=43-向量大小-1>4.3 向量大小</h2><p>batch size &lt; 64 or >64K时，性能显著下降。这是因为小向量不足以均摊解释开销，大向量无法放入CPU cache. 通常1k的尺寸对所有查询来说是一个很好的设置。</p><h1 id=5-数据并行执行simd-1>5 数据并行执行(SIMD)</h1><p>向量化引擎的基础是SIMD。AVX-512 SIMD指令集相比之前的AVX2或SSE4更强大，几乎所有操作都支持 掩码，并且增加了新指令，如压缩和扩展</p><h2 id=51-数据并行选择>5.1 数据并行选择</h2><p><img src=https://backendhouse.github.io/images/%E3%80%8AEverything%20You%20Always%20Wanted%20to%20Know%20About%20Compiled%20and%20Vectorized%20Queries%20But%20Were%20Afraid%20to%20Ask%E3%80%8B%E7%AC%94%E8%AE%B0/image-5.png alt="alt text"></p><p>现象：在dense input下，SIMD相比Scalar实现加速8.4x, 在sparse input下，SIMD相比Scalar实现加速2.7x。而在TPC-H Q6中，SIMD的加速比只有1.4x。
解释：由于选择向量导致的稀疏数据加载和步长变化导致cache-miss增多。TPC-H Q6的SIMD实现中，内存成为瓶颈，Q6的4个predicate中，只有第一个受益于SIMD，后面三个predicate计算都是基于选择向量的。</p><h2 id=52-数据并行hash-table-probe>5.2 数据并行hash table probe</h2><p>有两个使用SIMD的机会，计算哈希值，哈希表查找。
计算哈希值使用murmur2实现，该环节加速2.3x.
哈希表查找使用gather和其他SIMD指令加速，该环节加速1.4x</p><p>现象：TPC-H 连接查询整体提升却没有1.4x-2.3x如此明显
解释：随着hash table的增长，SIMD受益减少，执行成本由memory latency主导。</p><h2 id=54-总结>5.4 总结</h2><p>现象：基于AVX512的SIMD实现，在微基准测试中相比Scalar实现有8.4x的性能提升；但是在TPC-H查询中，性能提升小的多(如连接查询才1.1x)。
解释：因为大多数 OLAP 查询受限于数据访问， 而数据访问尚未(目前)从 SIMD 中获得太多好处，而不是 受限于计算，而计算是 SIMD 的优势</p><h1 id=6-查询内并行化>6 查询内并行化</h1><p>Morsel‐driven的并行性是为 HyPer开发的，因此 可以在 Typer 中非常直接地实现。
通过共享状态和屏障，Tectorwise实现表现出与Typer 相同的工作负载平衡并行化行为。</p><h2 id=62-多线程执行>6.2 多线程执行</h2><p>首先TW和Typer多线程下的性能有接近完美的可扩展性。其次线程数增加时，两个系统的性能差距会缩小。这表明多线程在隐藏一些微架构次优代码的缺点方面非常有效。</p><p><img src=https://backendhouse.github.io/images/%E3%80%8AEverything%20You%20Always%20Wanted%20to%20Know%20About%20Compiled%20and%20Vectorized%20Queries%20But%20Were%20Afraid%20to%20Ask%E3%80%8B%E7%AC%94%E8%AE%B0/image-6.png alt="alt text"></p><h1 id=8-总结>8 总结</h1><p><img src=https://backendhouse.github.io/images/%E3%80%8AEverything%20You%20Always%20Wanted%20to%20Know%20About%20Compiled%20and%20Vectorized%20Queries%20But%20Were%20Afraid%20to%20Ask%E3%80%8B%E7%AC%94%E8%AE%B0/image-7.png alt="alt text"></p><p><img src=https://backendhouse.github.io/images/%E3%80%8AEverything%20You%20Always%20Wanted%20to%20Know%20About%20Compiled%20and%20Vectorized%20Queries%20But%20Were%20Afraid%20to%20Ask%E3%80%8B%E7%AC%94%E8%AE%B0/image-8.png alt="alt text"></p><p>计算：代码生成在计算密集型查询方面表现更好， 因为它能够将数据保留在寄存器中，从而需要执行的指令更少。
并行数据访问：向量化执行在生成并行缓存未命中方面略好一些，因此在访问用于聚合或连接的大哈希表的内存 受限查询中具有一定优势。
SIMD：最近一直是硬件架构师用 来提高 CPU 性能的主要机制之一。理论上向量化执行更有可能从中受益。实际上，我们发现收益很小，因为大多数操作都由内存访问成本主导
并行化：使用morsel-driven并行调度，向量化和代码生成的引擎都可以在多核 CPU 上很好地扩展</p><p>向量化引擎的优势：</p><ul><li>无编译开销：因为所有的原语都是提前编译好的。代码生成中为了减少编译时间，可关闭某些llvm优化过程。</li><li>调优方便：运行时绑定到原语，而不是生成代码。代码生成中，为了方便调优，会在llvm ir之上引入抽象层，简化代码生成。</li><li>自适应执行：运行时根据数据特征切换原语。例如，在聚合过程中，将输入元组分区到多个选择向量中，每个分组键对应一个选择向量，当分组键较少时，可提升聚合性能。</li></ul><p>代码生成引擎的优势</p><ul><li>符合OLTP场景的需求，对fast stored procedures生成代码并编译。</li><li>多语言支持</li></ul></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>后端侠</span></p><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>2025-05-20</span></p></div><footer class=post-footer><div class=post-tags><a href=/tags/paper/>paper</a></div><nav class=post-nav><a class=prev href=/post/an-empirical-evaluation-of-columnar-storage-formats%E7%AC%94%E8%AE%B0/><i class="iconfont icon-left"></i><span class="prev-text nav-default">《An Empirical Evaluation of Columnar Storage Formats》笔记</span>
<span class="prev-text nav-mobile">上一篇</span></a>
<a class=next href=/post/golang%E5%BC%80%E5%8F%91%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/><span class="next-text nav-default">golang开发常用命令</span>
<span class="next-text nav-mobile">下一篇</span>
<i class="iconfont icon-right"></i></a></nav></footer></article></div><script src=https://utteranc.es/client.js repo=BackendHouse/hugo-comment issue-term=pathname theme=github-light crossorigin=anonymous async></script><noscript>Please enable JavaScript to view the <a href=https://github.com/utterance>comments powered by utterances.</a></noscript></div></main><footer id=footer class=footer><div class=social-links><a href=http://github.com/%e5%90%8e%e7%ab%af%e4%be%a0 class="iconfont icon-github" title=github></a><a href=https://backendhouse.github.io/index.xml type=application/rss+xml class="iconfont icon-rss" title=rss></a></div><div class=copyright><span class=power-by>由 <a class=hexo-link href=https://gohugo.io>Hugo</a> 强力驱动</span>
<span class=division>|</span>
<span class=theme-info>主题 -
<a class=theme-link href=https://github.com/olOwOlo/hugo-theme-even>Even</a></span>
<span class=copyright-year>&copy;
2020 -
2025<span class=heart><i class="iconfont icon-heart"></i></span><span>后端侠</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script src=https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin=anonymous></script><script type=text/javascript src=/js/main.min.c12618f9a600c40bd024996677e951e64d3487006775aeb22e200c990006c5c7.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-SYKLLYTW9K"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','G-SYKLLYTW9K');</script></body></html>