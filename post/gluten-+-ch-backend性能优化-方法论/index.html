<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Gluten + CH backend性能优化--方法论 - 后端技术小屋</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=author content="后端侠"><meta name=description content="Gluten + CH backend性能优化方法论 上篇我们介绍Gluten + CH backend性能开发中常用的工具链。本篇我们将展开讲讲Gluten + CH bac"><meta name=keywords content="Hugo,theme,后端侠"><meta name=generator content="Hugo 0.62.2 with theme even"><link rel=canonical href=https://backendhouse.github.io/post/gluten-+-ch-backend%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-%E6%96%B9%E6%B3%95%E8%AE%BA/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/manifest.json><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link href=/sass/main.min.a2095472a2a8d7ddda1334cf60051cbe40ed55f2467554bb6aa4c17c9bcd27a4.css rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin=anonymous><meta property="og:title" content="Gluten + CH backend性能优化--方法论"><meta property="og:description" content="Gluten + CH backend性能优化方法论 上篇我们介绍Gluten + CH backend性能开发中常用的工具链。本篇我们将展开讲讲Gluten + CH bac"><meta property="og:type" content="article"><meta property="og:url" content="https://backendhouse.github.io/post/gluten-+-ch-backend%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-%E6%96%B9%E6%B3%95%E8%AE%BA/"><meta property="article:published_time" content="2025-05-28T18:20:05+08:00"><meta property="article:modified_time" content="2025-05-28T18:20:05+08:00"><meta itemprop=name content="Gluten + CH backend性能优化--方法论"><meta itemprop=description content="Gluten + CH backend性能优化方法论 上篇我们介绍Gluten + CH backend性能开发中常用的工具链。本篇我们将展开讲讲Gluten + CH bac"><meta itemprop=datePublished content="2025-05-28T18:20:05+08:00"><meta itemprop=dateModified content="2025-05-28T18:20:05+08:00"><meta itemprop=wordCount content="12319"><meta itemprop=keywords content="gluten,clickhouse,性能优化,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Gluten + CH backend性能优化--方法论"><meta name=twitter:description content="Gluten + CH backend性能优化方法论 上篇我们介绍Gluten + CH backend性能开发中常用的工具链。本篇我们将展开讲讲Gluten + CH bac"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>后端技术小屋</a></div><div class=mobile-navbar-icon><span></span><span></span><span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=/><li class=mobile-menu-item>Home</li></a><a href=/post/><li class=mobile-menu-item>Archives</li></a><a href=/tags/><li class=mobile-menu-item>Tags</li></a><a href=/categories/><li class=mobile-menu-item>Categories</li></a><a href=/about/><li class=mobile-menu-item>About</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=/ class=logo>后端技术小屋</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/>Home</a></li><li class=menu-item><a class=menu-item-link href=/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=/tags/>Tags</a></li><li class=menu-item><a class=menu-item-link href=/categories/>Categories</a></li><li class=menu-item><a class=menu-item-link href=/about/>About</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>Gluten + CH backend性能优化--方法论</h1><div class=post-meta><span class=post-time>2025-05-28</span><div class=post-category><a href=/categories/gluten/>gluten</a></div></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class="post-toc-content always-active"><nav id=TableOfContents><ul><li><a href=#gluten--ch-backend性能优化方法论>Gluten + CH backend性能优化方法论</a><ul><li><a href=#发现性能问题>发现性能问题</a></li><li><a href=#识别系统短板>识别系统短板</a></li><li><a href=#分析性能瓶颈>分析性能瓶颈</a></li><li><a href=#优化系统性能>优化系统性能</a><ul><li><a href=#计划优化>计划优化</a></li><li><a href=#io优化>IO优化</a></li><li><a href=#计算优化>计算优化</a></li></ul></li><li><a href=#评估优化效果>评估优化效果</a></li><li><a href=#书籍推荐>书籍推荐</a></li><li><a href=#参考>参考</a></li></ul></li></ul></nav></div></div><div class=post-content><h1 id=gluten--ch-backend性能优化方法论>Gluten + CH backend性能优化方法论</h1><p><a href=https://backendhouse.github.io/post/gluten+ch-backend%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-%E5%B7%A5%E5%85%B7%E7%AF%87/>上篇</a>我们介绍Gluten + CH backend性能开发中常用的工具链。本篇我们将展开讲讲Gluten + CH backend性能优化的思路和方法论。</p><p>在进行性能优化的过程中，首先要做的就是找到性能有问题的case，如哪个sql执行的比较慢；然后定性的识别系统的短板到底在哪块，在spark任务的哪个阶段，哪个算子？在识别出性能短板后，接下来要定量分析具体的性能瓶颈，到底是哪个函数慢了，哪个循环慢了？最后在定量分析的基础上使用一定的技巧进行性能优化。优化完成后还要将改进版本和基线版本进行比较，评估优化效果，如果效果没有达到预期，还要回到前面重新发现性能问题，直到达到预期效果为止。</p><pre><code class=language-mermaid data-lang=mermaid>flowchart TD 
    A[发现性能问题] --&gt; B[识别系统短板] 
    B --&gt; C[分析性能瓶颈] 
    C --&gt; D[优化系统性能] 
    D --&gt; E[评估优化效果] 
    E -- 效果未达预期 --&gt; A 
    E -- 效果达预期 --&gt; F[优化闭环完成] 
</code></pre><h2 id=发现性能问题>发现性能问题</h2><p>首先要强调下性能优化的时机：有句话说的好，过早优化是万恶之源。只有当系统的功能完备之后，才有条件讨论性能优化。在错误的功能上进行性能优化是没有意义的。</p><p>其次什么样的问题才算性能问题呢？这个问题很宽泛，让我们把视角聚焦到执行Gluten + CH backend的Spark任务上。我们在生产环境灰度Gluten时，会比较Gluten和Vanilla Spark在执行相同任务时的性能差异。发生以下情况时，我们会认为是Gluten性能问题：</p><ul><li>Gluten执行的耗时和Vanilla Spark基本持平，或慢于Vanilla Spark。这说明Native Engine的向量化执行优势没有体现出来，系统中必然存在某些短板影响了整体性能。</li><li>Gluten执行的任务发生了OOM(out of memory)而Vanilla Spark正常。这说明Gluten执行时有executor进程的内存占用超过上限，需要优化其内存占用。优化内存占用也是性能优化的一个重要部分，但是它更多的和算子的spill实现相关，在这里我们不展开讨论。</li></ul><p>当然除了从生产环境中发现性能问题外，我们还可通过各种<a href=https://backendhouse.github.io/post/gluten+ch-backend%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-%E5%B7%A5%E5%85%B7%E7%AF%87/#benchmark%E5%B7%A5%E5%85%B7>Benchmark工具</a>来发现性能问题。例如CH提交性能优化相关PR时，会自动触发流水线中的性能测试，它会比较master版本和当前PR版本的性能差异，从而快速确认PR是否引入了新的性能问题。</p><p>找到执行时间较长的Spark任务后，我们需要进一步识别系统短板，分析性能瓶颈，优化系统性能。</p><h2 id=识别系统短板>识别系统短板</h2><p>当我们确定了哪个Spark任务有性能问题之后，接下来要做的就是该任务进行定性分析，找到性能短板，即它的性能卡在什么地方，哪个Stage，哪个任务，哪个算子？bound在哪些操作，是计算还是IO?</p><p>我们可以使用<a href=https://backendhouse.github.io/post/gluten+ch-backend%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-%E5%B7%A5%E5%85%B7%E7%AF%87/#spark-web-ui>Spark Web UI</a>来帮助我们查看不同层级 SQL -> Plan -> Stage -> Task -> Operator的全局执行情况，也可通过<a href=https://backendhouse.github.io/post/gluten+ch-backend%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-%E5%B7%A5%E5%85%B7%E7%AF%87/#spark%E6%97%A5%E5%BF%97>Spark日志</a>深入到每个具体Task中，查看Native Engine的计算逻辑和性能指标。</p><h2 id=分析性能瓶颈>分析性能瓶颈</h2><p>当我们确定了Spark任务大概瓶颈在哪块时，接下来分两步：</p><ol><li>第一步，根据生产环境的Case,构造能体现其性能短板的简化Case，在开发环境中复现，这样做的理由有：</li></ol><ul><li>生产环境数据量太大，执行一个任务可能需要数个小时，不适合后续的定量分析</li><li>生产环境的负载不稳定，干扰因素太多，可能会影响性能分析的准确性</li><li>生产环境一般是分布式集群，性能调优的工具链不一定完善</li></ul><p><strong>注意</strong>, 构造开发环境的Case时，应当尽量放大性能短板所在的部分，而适当简化其他部分。例如，如果一个Spark SQL的性能短板在某个Subquery上，那么我们可将该Subquery提取出来，构造一个独立的SQL来复现性能问题；同样的，如果性能短板在某个算子上，我们也可以将该算子提取出来，而简化其他算子。这样做的好处是减少了不必要的干扰因素，方便后续的定量分析。构造简化Case并不是一蹴而就的，可能要经过反复试错。</p><ol start=2><li>第二步，我们在开发环境中运行简化Case, 并使用<a href=https://backendhouse.github.io/post/gluten+ch-backend%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-%E5%B7%A5%E5%85%B7%E7%AF%87>性能调优工具</a>进行定量分析，生成火焰图，找到代码级或指令级的性能瓶颈。这里推荐使用Intel Vtune进行分析，因为它的功能比较完善且使用相对简单，能查看火焰图、源代码、汇编代码，能进行热点分析、CPU微架构分析、内存访问分析和内存消费分析。</li></ol><h2 id=优化系统性能>优化系统性能</h2><p>到了这一步，我们不管在系统的宏观还是微观视角，都已经有了比较清晰的性能瓶颈定位。接下来就是要使用一定的技巧进行性能优化。</p><p>在<a href=https://backendhouse.github.io/post/gluten+ch-backend%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-%E9%97%AE%E9%A2%98%E4%B8%8E%E6%8C%91%E6%88%98%E7%AF%87/>Gluten+CH backend性能优化&ndash;问题与挑战篇</a>中，我们已经介绍了Gluten + CH backend性能优化的常见问题和挑战。接下来我们将展开讲讲如何针对这些问题进行性能优化。</p><h3 id=计划优化>计划优化</h3><p>在<a href=https://backendhouse.github.io/post/gluten+ch-backend%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-%E9%97%AE%E9%A2%98%E4%B8%8E%E6%8C%91%E6%88%98%E7%AF%87/#%E8%AE%A1%E5%88%92%E4%BC%98%E5%8C%96%E4%B8%8D%E5%85%85%E5%88%86>前面</a>我们提到了Gluten + CH backend的计划优化面临的问题与挑战：由于各种各样的原因，最终Native Engine执行的物理计划并不是最优的。为了解决这个问题，我们在Spark和Gluten通用优化规则的基础上，增加了针对CH backend的优化规则，尽量使Native Engine执行的物理计划更优。</p><p>优化规则大致可分为两种， 一种是作用于逻辑计划，一种作用于物理计划，实际应用中两者是相辅相成的。</p><p>Spark AQE(Adaptive Query Execution)是Spark SQL中的优化技术，利用运行时的统计信息来选择最高效的查询执行计划，如通过合并减少shuffle分区数量，将sort-merge join转化为broadcast join，优化数据倾斜等等。Spark AQE提供了运行时的统计信息，如算子输出行数，可用于Gluten中的join reorder优化，或根据统计信息选择合适的CH join算法实现。</p><p>通过优化执行计划可以减少不必要的计算和数据传输，对提升Spark任务性能起到了事半功倍的效果。因此在优化Spark任务时，应当首先考虑是否有计划优化的空间。</p><h3 id=io优化>IO优化</h3><p>在Spark中，涉及到IO的操作主要是Scan、Shuffle和Insert算子。对于Shuffle算子，我们使用Apache Celeborn作为RSS(Remote Shuffle Service)来实现列式Shuffle，可参考<a href=https://developer.aliyun.com/article/1266372>Gluten + Celeborn: 让Native Spark 拥抱Cloud Native</a>。对于Insert算子，我们和社区分别实现了<a href=https://github.com/apache/incubator-gluten/pull/2553>ORC</a>/Parquet(<a href=https://github.com/apache/incubator-gluten/pull/1595>https://github.com/apache/incubator-gluten/pull/1595</a>)表的列式写入功能，其IO性能是Vanilla的两倍。因此这里我们不展开讨论Shuffle和Insert算子的优化，而把视角聚焦到占比更大Scan算子上。</p><p>优化Scan算子时，我们可以从以下几个方面入手：</p><h4 id=降低io请求次数和请求量>降低IO请求次数和请求量</h4><p>因此Scan算子中，会频繁对远程IO进行请求，导致网络带宽和远程存储的压力过大。我们可以通过以下方式来减少IO请求次数和请求量：</p><ul><li><strong>列裁剪</strong>：只读取需要的列数据，避免读取不必要的数据。可以通过Column Pruning来实现。注意只有ORC、Parquet这种列式存储格式支持列裁剪。那么什么是列裁剪呢？列裁剪是指在读取数据时，只读取查询中需要的列，而不是读取整个表的所有列。这样可以减少IO请求量，提高性能。列式存储格式之所以能支持列裁剪，是因为它将数据按列存储，而不是按行存储。例如，文件中包含a, b, c, d四列数据，但是查询只需要a和c两列数据，那么列裁剪就只会读取a和c两列数据，而跳过b和d两列数据。</li><li><strong>行裁剪</strong>：只读取需要的行数据，避免读取不必要的数据。可以通过Predicate Pushdown来实现。同样只对ORC、Parquet的列式存储格式有效。行裁剪是指在读取数据时，只读取满足查询条件的行，而不是读取整个文件的所有行，同样可以减少IO请求量，提高性能。那么行裁剪是如何实现的呢？对于最新版本的Parquet格式，它的文件级别、rowgroup级别和page级别都定义了minmax index(page级别可选)和bloom filter(可选)，某列的minmax index是指该列在对应层级所有数据中的最大值、最小值、Null Count等信息,minmax index可用于快速过滤不满足范围查询的行，而Bloom Filter用于快速过滤不满足点查条件的概率数据结构。对于ORC格式，它的文件级别、stripe级别和rowgroup级别都定义了minmax index和bloom filter，原理类似。</li></ul><p><img src=https://backendhouse.github.io/images/Gluten%20+%20CH%20backend%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96--%E6%96%B9%E6%B3%95%E8%AE%BA/image.png alt="alt text"></p><ul><li><strong>编码优化</strong>：使用更高效的编码方式来减少数据量。例如，ORC和Parquet格式都支持多种编码方式，如Run Length Encoding(RLE)、Dictionary Encoding等，这些编码方式结合默认的压缩算法可以有效减少列式数据的字节数，从而减少IO请求量，提升Scan算子性能。</li></ul><p>我们可以看到，上面三种优化方式，列裁剪、行裁剪、编码优化，都是利用列式存储的优秀设计来尽可能减少查询的IO请求次数和请求量，他们的核心思想是尽量不读取不需要的数据。这也从侧面说明了ORC和Parquet相比Text、JSON格式在性能上的优越性。因此生产环境中应当尽量使用ORC或Parquet作为Hive表的存储格式。</p><h4 id=异步io模型>异步IO模型</h4><p>在Gluten的早期实现中，无论是Text、ORC还是Parquet文件，都是使用libhdfs3库的同步IO模型进行读取的。同步IO模型会阻塞工作线程，导致CPU空闲，无法充分利用CPU资源。为了提高Scan算子运行时的CPU利用率，我们可以使用异步IO模型来替代同步IO模型，在CPU计算时通过后台线程异步读取下一次的数据块，从而将IO延迟隐藏在CPU计算中。</p><p>但是不同格式下，由于文件的存储结构不同，CH中native reader读取模式不同，异步IO模型的实现也有所不同：</p><ul><li><strong>ORC/Parquet</strong>: ORC/Parquet的读取模式是多次小范围随机读。ORC文件由多个Stripe组成，Parquet文件由d多个Row Group组成。当CPU在处理当前ORC Stripe或Parquet RowGroup时，可以通过异步IO模型来读取下一个ORC Stripe或Parquet RowGroup的数据。等到处理下个ORC Stripe或Parquet RowGroup时，数据已经准备好了，可以直接使用。注意由于上面的列裁剪和行裁剪，ORC Stripe或Parquet RowGroup一般要读取多个IO range, 这里需要根据一定的阈值对相邻的IO range进行合并，避免远程IO请求过多影响整体读取性能。</li><li><strong>Text</strong>： Text的读取模式是顺序读。Text格式不存在行裁剪和列裁剪优化，因此异步IO模型只需读取连续且相邻的IO range。在处理当前文件段时，可通过异步IO模型来读取下一个文件段的数据。等到处理下个文件段时，数据已经在内存中了。</li></ul><h4 id=文件分区读>文件分区读</h4><p>我们知道，Spark为了提升task的并行度，会将HDFS file拆分成多个file split，每个任务读取一个file split，从而提升任务的并行度。对于ORC和Parquet格式，这些file split可以对应到一个或多个Stripe或Row Group。而对于Text格式，一个file split对应着一个文件段。</p><p>由于历史原因，我们的生产环境存在一些Text格式的Hive表，它们通常使用bzip2压缩算法。但是在CH实现中，bzip2压缩文件不支持分区读，这限制了Spark任务的并行度。我们在<a href=https://github.com/apache/incubator-gluten/pull/7638>Gluten中扩展了bzip2的分区读</a>功能，实现了对bzip2文件任意范围的分区读。</p><p>注意，分区读虽然能提升任务的并行度，但是需要妥善处理好两个相邻file split之间的边界问题。当然ORC/Parquet列式存储不存在这种担忧。但是在Text格式中，file split边界和行边界的错位可能会导致数据不完整或数据错乱，如果再叠加上bzip2压缩，要处理的边界问题会更加复杂，需要考虑file split边界、行边界、bzip2压缩块边界在不同位置下的情况，保证数据不多不少不错。</p><h3 id=计算优化>计算优化</h3><p>在Spark任务中，CPU计算占据了大部分的执行时间，因此计算优化是提升Gluten性能的关键。在实际优化中，我们一方面替换更高效的底层算法或第三方库，另一方面通过大循环的执行效率</p><h4 id=替换更高效的算法或库>替换更高效的算法或库</h4><p>Native Engine底层依赖了大量的第三方库或算法。以CH为例，读取ORC文件依赖arrow和orc库, 读取HDFS文件依赖libhdfs3, JSON解析依赖simdjson和rapidjson，实现join算法有单线程的hash join、并行的parallel hash join、支持spill功能的grace hash join、sort merge join等。</p><p>通过替换更高效的算法或库，可以在改动较小的情况下，优化系统的性能。
例如</p><ul><li>CH中默认使用simdjson替代rapidjson来解析JSON文件，simdjson是一个基于SIMD指令集的高性能JSON解析库，它的性能是后者的<a href=https://simdjson.org/>4倍</a>。通过它的向量化能力大幅提高了CH中JSON相关函数的性能。</li><li>CH中通过<a href=https://github.com/ClickHouse/ClickHouse/pull/61632>改进UTF8字符串函数的实现算法</a>，提升了它们处理字符串的性能。在现实世界中，很多字符串都是ASCII字符。如果按照UTF8的方式处理ASCII字符，虽然结果没问题，但是无法利用CPU向量化的能力。我们实现了自适应算法：对于一个输入字符串向量，首先通过SIMD指令判断其中是否包含非ASCII字符，如果没有，则按照ASCII字符的方式向量化的处理字符串；如果有，则使用UTF8字符的方式处理字符串。</li></ul><h4 id=大循环优化>大循环优化</h4><p>在Native Engine中，CPU计算主要体现在大循环上。通常情况下，我们在一个大循环中读取一个或多个输入向量，并且将结果填充到输出向量中，循环中每次迭代对应着输入输出向量中的一行数据。在Gluten中，CH处理向量的默认batch size是8192，在这个量级下，循环中任何微小的性能瑕疵都会影响大循环的整体性能，反过来说，循环中任何一个了不起眼的小优化都可能带来显著的性能提升。</p><p>优化大循环主要从以下几个方面入手：</p><h5 id=消除分支>消除分支</h5><p>关于大循环中分支对性能的危害性，我们在<a href=https://backendhouse.github.io/post/gluten+ch-backend%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-%E9%97%AE%E9%A2%98%E4%B8%8E%E6%8C%91%E6%88%98%E7%AF%87/#cache-miss>前面</a>已经介绍。</p><p>以下是几种解决方案：</p><ol><li>branchless编程</li></ol><p>branchless编程是指通过数学运算或位运算来替代条件分支，从而消除分支对性能的影响。在现代CPU中，乘法和加法指令的延迟都很低，通常在1-3个周期内完成，而分支指令的延迟可能高达几十个周期，因此在大循环中branchless优化带来的收益还是很明显的。</p><p>例1</p><div class=highlight><pre style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp>size_t a_index <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>, b_index <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>; 
<span style=color:#ff79c6>for</span> (size_t i <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>; i <span style=color:#ff79c6>&lt;</span> n; <span style=color:#ff79c6>+</span><span style=color:#ff79c6>+</span>i) { 
    c[i] <span style=color:#ff79c6>=</span> cond[i] <span style=color:#ff79c6>?</span> <span style=color:#ff79c6>static_cast</span><span style=color:#ff79c6>&lt;</span>T<span style=color:#ff79c6>&gt;</span>(a[a_index<span style=color:#ff79c6>+</span><span style=color:#ff79c6>+</span>]) <span style=color:#ff79c6>:</span> <span style=color:#ff79c6>static_cast</span><span style=color:#ff79c6>&lt;</span>T<span style=color:#ff79c6>&gt;</span>(b[b_index<span style=color:#ff79c6>+</span><span style=color:#ff79c6>+</span>]); 
} 
</code></pre></div><p>通过branchless优化后：</p><div class=highlight><pre style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp>size_t a_index <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>, b_index <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>; 
<span style=color:#ff79c6>for</span> (size_t i <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>; i <span style=color:#ff79c6>&lt;</span> n; <span style=color:#ff79c6>+</span><span style=color:#ff79c6>+</span>i) { 
    c[i] <span style=color:#ff79c6>=</span> <span style=color:#ff79c6>static_cast</span><span style=color:#ff79c6>&lt;</span>T<span style=color:#ff79c6>&gt;</span>(a[a_index]) <span style=color:#ff79c6>*</span> <span style=color:#ff79c6>!</span><span style=color:#ff79c6>!</span>cond[i] <span style=color:#ff79c6>+</span> <span style=color:#ff79c6>static_cast</span><span style=color:#ff79c6>&lt;</span>T<span style=color:#ff79c6>&gt;</span>(b[b_index]) <span style=color:#ff79c6>*</span> <span style=color:#ff79c6>!</span>cond[i]; 
    a_index <span style=color:#ff79c6>+</span><span style=color:#ff79c6>=</span> <span style=color:#ff79c6>!</span>cond[i]; 
    b_index <span style=color:#ff79c6>+</span><span style=color:#ff79c6>=</span> <span style=color:#ff79c6>!</span><span style=color:#ff79c6>!</span>cond[i]; 
} 
</code></pre></div><p>其中``!!cond[i]<code>和</code>!cond[i]`分别将条件转换为0或1，从而实现了条件分支的数学计算。</p><p>例2</p><div class=highlight><pre style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=color:#ff79c6>for</span> (size_t i <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>; i <span style=color:#ff79c6>&lt;</span> n; <span style=color:#ff79c6>+</span><span style=color:#ff79c6>+</span>i) { 
    c[i] <span style=color:#ff79c6>=</span> (a[i] <span style=color:#ff79c6>&gt;</span> <span style=color:#bd93f9>10</span>) <span style=color:#ff79c6>&amp;</span><span style=color:#ff79c6>&amp;</span> (b[i] <span style=color:#ff79c6>&lt;</span> <span style=color:#bd93f9>20</span>); 
} 
</code></pre></div><p><code>&&</code>逻辑与计算会在<a href=https://godbolt.org/z/v35nrxhvc>底层汇编代码</a>中引入分支跳转。为了消除分支跳转</p><p>我们可以将逻辑与转化为数学计算</p><div class=highlight><pre style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=color:#ff79c6>for</span> (size_t i <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>; i <span style=color:#ff79c6>&lt;</span> n; <span style=color:#ff79c6>+</span><span style=color:#ff79c6>+</span>i) { 
    c[i] <span style=color:#ff79c6>=</span> (a[i] <span style=color:#ff79c6>&gt;</span> <span style=color:#bd93f9>10</span>) <span style=color:#ff79c6>&amp;</span> (b[i] <span style=color:#ff79c6>&lt;</span> <span style=color:#bd93f9>20</span>); 
} 
</code></pre></div><p><strong>注意</strong>，clang或gcc编译器在开启<code>-O2</code>或更高优化级别时，会将一些简单的分支逻辑自动优化为branchless代码，如将三目运算符转化成<a href=https://kristerw.github.io/2022/05/24/branchless/>cmov指令</a>。因此当你在开启branchless优化之前，请先检查编译器是否已进行过自动优化，推荐使用<a href=https://godbolt.org/>Compiler Explorer</a>来查看指定编译器和编译选项下生成的汇编代码。</p><p><a href=https://graphics.stanford.edu/~seander/bithacks.html>bithacks</a>中介绍了一系列位运算技巧，可以帮我我们消除分支跳转。</p><ol start=2><li>分支上提到循环外</li></ol><p>分支上提是指将循环中的分支判断移到循环外部，从而减少循环中的分支判断次数。这样可以减少分支预测失败的概率，提高CPU流水线的效率。</p><p>这里有一个实际的<a href=https://github.com/ClickHouse/ClickHouse/pull/67794>例子</a></p><p><img src=https://backendhouse.github.io/images/Gluten%20+%20CH%20backend%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96--%E6%96%B9%E6%B3%95%E8%AE%BA/image-1.png alt="alt text"></p><p>以上是CH中orc reader将orc string列转化为CH string列的代码片段。
在优化前，循环中的if-else条件引入了3个branch，如果if条件为true, 对应行中string值非Null，按照非null的方式处理，否则按照null的方式处理。if中的<code>!orc_str_column->hasNulls</code>是和循环无关的，在我们的改进中，将其移到了循环外部。改进后一个循环分裂成了两个循环，第一个循环处理所有行都非Null的情况，第二个循环处理其他情况，第一个循环没有分支跳转，第二个循环只有2个branch。</p><h5 id=消除虚函数调用>消除虚函数调用</h5><p>虚函数常用于实现多态中的动态绑定，它允许在运行时根据对象的实际类型调用相应的函数。然而，虚函数调用会引入额外的开销，如指针间接寻址、分支预测失败、无法内联优化等。大循环中中的虚函数调用绝对是性能杀手。</p><ol><li>通过CRTP(Curiously Recurring Template Pattern)进行devirtualize</li></ol><p>CRTP是一种C++编程技巧，它允许在编译时确定类型，从而消除虚函数调用的开销。通过CRTP，我们可以将虚函数调用转化为静态多态，从而避免了指针间接寻址和分支预测失败的问题。</p><p>还是以CH中向量的实现为例, <code>IColumn</code>定义了CH中向量的接口，CH中所有向量的实现都集成自<code>IColumn</code>，如<code>ColumnVector</code>, <code>ColumnString</code>, <code>ColumnArray</code>等。<code>IColumn</code>中定义了两个虚函数接口</p><ul><li><code>fillFromBlocksAndRowNumbers</code>，用于从多个Block和行号填充向量的值, 这是一个批量计算操作。</li><li><code>insertFrom</code>，用于将其他向量的某个元素插入到当前向量中。</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=color:#6272a4>/// Declares interface to store columns in memory. 
</span><span style=color:#6272a4></span><span style=color:#ff79c6>class</span> <span style=color:#50fa7b>IColumn</span> <span style=color:#ff79c6>:</span> <span style=color:#ff79c6>public</span> COW<span style=color:#ff79c6>&lt;</span>IColumn<span style=color:#ff79c6>&gt;</span> 
{ 
<span style=color:#ff79c6>public</span><span style=color:#ff79c6>:</span> 
    <span style=color:#6272a4>/// Appends n-th element from other column with the same type. 
</span><span style=color:#6272a4></span>    <span style=color:#6272a4>/// Is used in merge-sort and merges. It could be implemented in inherited classes more optimally than default implementation. 
</span><span style=color:#6272a4></span>    <span style=color:#ff79c6>virtual</span> <span style=color:#8be9fd>void</span> insertFrom(<span style=color:#ff79c6>const</span> IColumn <span style=color:#ff79c6>&amp;</span> src, size_t n); 
 
    <span style=color:#6272a4>/// Fills column values from list of blocks and row numbers 
</span><span style=color:#6272a4></span>    <span style=color:#6272a4>/// `blocks` and `row_nums` must have same size 
</span><span style=color:#6272a4></span>    <span style=color:#ff79c6>virtual</span> <span style=color:#8be9fd>void</span> <span style=color:#50fa7b>fillFromBlocksAndRowNumbers</span>(<span style=color:#ff79c6>const</span> DataTypePtr <span style=color:#ff79c6>&amp;</span> type, size_t source_column_index_in_block, <span style=color:#ff79c6>const</span> std<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>vector<span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>const</span> Block <span style=color:#ff79c6>*</span><span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>&amp;</span> blocks, <span style=color:#ff79c6>const</span> std<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>vector<span style=color:#ff79c6>&lt;</span>UInt32<span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>&amp;</span> row_nums); 
}; 
 
<span style=color:#6272a4>/// Fills column values from list of blocks and row numbers 
</span><span style=color:#6272a4></span><span style=color:#6272a4>/// Implementation with concrete column type allows to de-virtualize col-&gt;insertFrom() calls 
</span><span style=color:#6272a4></span><span style=color:#ff79c6>template</span> <span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>typename</span> ColumnType<span style=color:#ff79c6>&gt;</span> 
<span style=color:#ff79c6>static</span> <span style=color:#8be9fd>void</span> fillColumnFromBlocksAndRowNumbers(ColumnType <span style=color:#ff79c6>*</span> col, <span style=color:#ff79c6>const</span> DataTypePtr <span style=color:#ff79c6>&amp;</span> type, size_t source_column_index_in_block, <span style=color:#ff79c6>const</span> std<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>vector<span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>const</span> Block <span style=color:#ff79c6>*</span><span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>&amp;</span> blocks, <span style=color:#ff79c6>const</span> std<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>vector<span style=color:#ff79c6>&lt;</span>UInt32<span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>&amp;</span> row_nums) 
{ 
    chassert(blocks.size() <span style=color:#ff79c6>=</span><span style=color:#ff79c6>=</span> row_nums.size()); 
    col<span style=color:#ff79c6>-</span><span style=color:#ff79c6>&gt;</span>reserve(col<span style=color:#ff79c6>-</span><span style=color:#ff79c6>&gt;</span>size() <span style=color:#ff79c6>+</span> blocks.size()); 
    <span style=color:#ff79c6>for</span> (size_t j <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>; j <span style=color:#ff79c6>&lt;</span> blocks.size(); <span style=color:#ff79c6>+</span><span style=color:#ff79c6>+</span>j) 
    { 
        <span style=color:#ff79c6>if</span> (blocks[j]) 
            col<span style=color:#ff79c6>-</span><span style=color:#ff79c6>&gt;</span>insertFrom(<span style=color:#ff79c6>*</span>blocks[j]<span style=color:#ff79c6>-</span><span style=color:#ff79c6>&gt;</span>getByPosition(source_column_index_in_block).column, row_nums[j]); 
        <span style=color:#ff79c6>else</span> 
            type<span style=color:#ff79c6>-</span><span style=color:#ff79c6>&gt;</span>insertDefaultInto(<span style=color:#ff79c6>*</span>col); 
    } 
} 
 
<span style=color:#6272a4>/// Fills column values from list of blocks and row numbers 
</span><span style=color:#6272a4></span><span style=color:#8be9fd>void</span> IColumn<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>fillFromBlocksAndRowNumbers(<span style=color:#ff79c6>const</span> DataTypePtr <span style=color:#ff79c6>&amp;</span> type, size_t source_column_index_in_block, <span style=color:#ff79c6>const</span> std<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>vector<span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>const</span> Block <span style=color:#ff79c6>*</span><span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>&amp;</span> blocks, <span style=color:#ff79c6>const</span> std<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>vector<span style=color:#ff79c6>&lt;</span>UInt32<span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>&amp;</span> row_nums) 
{ 
    fillColumnFromBlocksAndRowNumbers(<span style=color:#ff79c6>this</span>, type, source_column_index_in_block, blocks, row_nums); 
} 
</code></pre></div><p>可以看到<code>IColumn::fillFromBlocksAndRowNumbers</code>的实现中调用了<code>fillColumnFromBlocksAndRowNumbers</code>函数，而后者是一个模板函数，传入<code>fillColumnFromBlocksAndRowNumbers</code>中的<code>col</code>参数类型是<code>IColumn *</code>, 大循环中的<code>col->insertFrom</code>调用是虚函数调用！</p><p>为了去除循环中<code>col->insertFrom</code>虚函数调用开销，CH引入了<code>IColumnHelper</code>类，它是一个CRTP类模板，继承自<code>IColumn</code>。模板中override了<code>fillFromBlocksAndRowNumbers</code>方法，提供了一个更高效的实现。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=color:#6272a4>// Implement methods to devirtualize some calls of IColumn in final descendents. 
</span><span style=color:#6272a4></span><span style=color:#6272a4>/// `typename Parent` is needed because some columns don&#39;t inherit IColumn directly. 
</span><span style=color:#6272a4></span><span style=color:#6272a4>/// See ColumnFixedSizeHelper for example. 
</span><span style=color:#6272a4></span><span style=color:#ff79c6>template</span> <span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>typename</span> Derived, <span style=color:#ff79c6>typename</span> Parent <span style=color:#ff79c6>=</span> IColumn<span style=color:#ff79c6>&gt;</span> 
<span style=color:#ff79c6>class</span> <span style=color:#50fa7b>IColumnHelper</span> <span style=color:#ff79c6>:</span> <span style=color:#ff79c6>public</span> Parent 
{ 
<span style=color:#ff79c6>public</span><span style=color:#ff79c6>:</span> 
    <span style=color:#6272a4>/// Fills column values from list of blocks and row numbers 
</span><span style=color:#6272a4></span>    <span style=color:#6272a4>/// `blocks` and `row_nums` must have same size 
</span><span style=color:#6272a4></span>    <span style=color:#8be9fd>void</span> fillFromBlocksAndRowNumbers(<span style=color:#ff79c6>const</span> DataTypePtr <span style=color:#ff79c6>&amp;</span> type, size_t source_column_index_in_block, <span style=color:#ff79c6>const</span> std<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>vector<span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>const</span> Block <span style=color:#ff79c6>*</span><span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>&amp;</span> blocks, <span style=color:#ff79c6>const</span> std<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>vector<span style=color:#ff79c6>&lt;</span>UInt32<span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>&amp;</span> row_nums) <span style=color:#ff79c6>override</span>; 
}; 
 
<span style=color:#6272a4>/// Fills column values from list of blocks and row numbers 
</span><span style=color:#6272a4></span><span style=color:#ff79c6>template</span> <span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>typename</span> Derived, <span style=color:#ff79c6>typename</span> Parent<span style=color:#ff79c6>&gt;</span> 
<span style=color:#8be9fd>void</span> IColumnHelper<span style=color:#ff79c6>&lt;</span>Derived, Parent<span style=color:#ff79c6>&gt;</span><span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>fillFromBlocksAndRowNumbers(<span style=color:#ff79c6>const</span> DataTypePtr <span style=color:#ff79c6>&amp;</span> type, size_t source_column_index_in_block, <span style=color:#ff79c6>const</span> std<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>vector<span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>const</span> Block <span style=color:#ff79c6>*</span><span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>&amp;</span> blocks, <span style=color:#ff79c6>const</span> std<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>vector<span style=color:#ff79c6>&lt;</span>UInt32<span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>&amp;</span> row_nums) 
{ 
    <span style=color:#ff79c6>auto</span> <span style=color:#ff79c6>&amp;</span> self <span style=color:#ff79c6>=</span> <span style=color:#ff79c6>static_cast</span><span style=color:#ff79c6>&lt;</span>Derived <span style=color:#ff79c6>&amp;</span><span style=color:#ff79c6>&gt;</span>(<span style=color:#ff79c6>*</span><span style=color:#ff79c6>this</span>); 
    fillColumnFromBlocksAndRowNumbers(<span style=color:#ff79c6>&amp;</span>self, type, source_column_index_in_block, blocks, row_nums); 
} 
</code></pre></div><p>在调用静态模板函数<code>fillColumnFromBlocksAndRowNumbers</code>前，<code>IColumnHelper::fillFromBlocksAndRowNumbers</code>首先会将<code>this</code>指针转换为<code>Derived*</code>类型，<code>Derived</code>是<code>IColumnHelper</code>的派生类类型。通过引入CRTP，我们可以在编译期确定循环中<code>col->insertFrom</code>的具体类型，从而消除<code>insertFrom</code>的虚函数调用开销。【相关PR](<a href=https://github.com/ClickHouse/ClickHouse/pull/77350>https://github.com/ClickHouse/ClickHouse/pull/77350</a>)</p><h5 id=类型特化处理>类型特化处理</h5><p>类型特化处理也是在CH中广泛使用的优化技巧。它的核心思想是，每次处理<code>IColumn*</code>类型的向量前，先判断向量的具体类型，然后根据具体类型调用不同的处理函数，相当于把循环中的动态绑定逻辑，转移到循环外部。这样循环中的虚函数调用开销就消失了，虽然循环外部增加了一个类型判断的开销，但是由于循环外部的类型判断只执行一次，而循环内部的虚函数调用可能会执行数千次，新增的类型判断开销显得微不足道。</p><p>还是以CH为例，如下所示，<code>ColumnArray</code>表示CH中的数组向量，<code>ColumnArray::filter</code>方法用于对数组向量进行过滤操作。<code>ColumnArray</code>在编译期是无法知晓其嵌套类型的，因此在<code>filter</code>方法中需要根据<code>data</code>的具体类型进行判断，然后调用不同的处理函数，在这些处理函数中，会将<code>data</code>转换为具体的向量类型，执行响应的过滤操作。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp>ColumnPtr ColumnArray<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>filter(<span style=color:#ff79c6>const</span> Filter <span style=color:#ff79c6>&amp;</span> filt, ssize_t result_size_hint) <span style=color:#ff79c6>const</span> 
{ 
    <span style=color:#ff79c6>if</span> (typeid_cast<span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>const</span> ColumnUInt8 <span style=color:#ff79c6>*</span><span style=color:#ff79c6>&gt;</span>(data.get())) 
        <span style=color:#ff79c6>return</span> filterNumber<span style=color:#ff79c6>&lt;</span>UInt8<span style=color:#ff79c6>&gt;</span>(filt, result_size_hint); 
    <span style=color:#ff79c6>if</span> (typeid_cast<span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>const</span> ColumnUInt16 <span style=color:#ff79c6>*</span><span style=color:#ff79c6>&gt;</span>(data.get())) 
        <span style=color:#ff79c6>return</span> filterNumber<span style=color:#ff79c6>&lt;</span>UInt16<span style=color:#ff79c6>&gt;</span>(filt, result_size_hint); 
 
 
    <span style=color:#ff79c6>if</span> (typeid_cast<span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>const</span> ColumnFloat32 <span style=color:#ff79c6>*</span><span style=color:#ff79c6>&gt;</span>(data.get())) 
        <span style=color:#ff79c6>return</span> filterNumber<span style=color:#ff79c6>&lt;</span>Float32<span style=color:#ff79c6>&gt;</span>(filt, result_size_hint); 
    <span style=color:#ff79c6>if</span> (typeid_cast<span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>const</span> ColumnFloat64 <span style=color:#ff79c6>*</span><span style=color:#ff79c6>&gt;</span>(data.get())) 
        <span style=color:#ff79c6>return</span> filterNumber<span style=color:#ff79c6>&lt;</span>Float64<span style=color:#ff79c6>&gt;</span>(filt, result_size_hint); 
 
    <span style=color:#ff79c6>if</span> (typeid_cast<span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>const</span> ColumnDecimal<span style=color:#ff79c6>&lt;</span>Decimal32<span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>*</span><span style=color:#ff79c6>&gt;</span>(data.get())) 
        <span style=color:#ff79c6>return</span> filterNumber<span style=color:#ff79c6>&lt;</span>Decimal32<span style=color:#ff79c6>&gt;</span>(filt, result_size_hint); 
    <span style=color:#ff79c6>if</span> (typeid_cast<span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>const</span> ColumnDecimal<span style=color:#ff79c6>&lt;</span>Decimal64<span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>*</span><span style=color:#ff79c6>&gt;</span>(data.get())) 
        <span style=color:#ff79c6>return</span> filterNumber<span style=color:#ff79c6>&lt;</span>Decimal64<span style=color:#ff79c6>&gt;</span>(filt, result_size_hint); 
 
    <span style=color:#ff79c6>if</span> (typeid_cast<span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>const</span> ColumnString <span style=color:#ff79c6>*</span><span style=color:#ff79c6>&gt;</span>(data.get())) 
        <span style=color:#ff79c6>return</span> filterString(filt, result_size_hint); 
} 
 
<span style=color:#ff79c6>template</span> <span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>typename</span> T<span style=color:#ff79c6>&gt;</span> 
ColumnPtr ColumnArray<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>filterNumber(<span style=color:#ff79c6>const</span> Filter <span style=color:#ff79c6>&amp;</span> filt, ssize_t result_size_hint) <span style=color:#ff79c6>const</span> 
{ 
    <span style=color:#ff79c6>using</span> ColVecType <span style=color:#ff79c6>=</span> ColumnVectorOrDecimal<span style=color:#ff79c6>&lt;</span>T<span style=color:#ff79c6>&gt;</span>; 
 
    <span style=color:#ff79c6>if</span> (getOffsets().empty()) 
        <span style=color:#ff79c6>return</span> ColumnArray<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>create(data); 
 
    <span style=color:#ff79c6>auto</span> res <span style=color:#ff79c6>=</span> ColumnArray<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>create(data<span style=color:#ff79c6>-</span><span style=color:#ff79c6>&gt;</span>cloneEmpty()); 
 
    <span style=color:#ff79c6>auto</span> <span style=color:#ff79c6>&amp;</span> res_elems <span style=color:#ff79c6>=</span> assert_cast<span style=color:#ff79c6>&lt;</span>ColVecType <span style=color:#ff79c6>&amp;</span><span style=color:#ff79c6>&gt;</span>(res<span style=color:#ff79c6>-</span><span style=color:#ff79c6>&gt;</span>getData()).getData(); 
    Offsets <span style=color:#ff79c6>&amp;</span> res_offsets <span style=color:#ff79c6>=</span> res<span style=color:#ff79c6>-</span><span style=color:#ff79c6>&gt;</span>getOffsets(); 
 
    filterArraysImpl<span style=color:#ff79c6>&lt;</span>T<span style=color:#ff79c6>&gt;</span>(assert_cast<span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>const</span> ColVecType <span style=color:#ff79c6>&amp;</span><span style=color:#ff79c6>&gt;</span>(<span style=color:#ff79c6>*</span>data).getData(), getOffsets(), res_elems, res_offsets, filt, result_size_hint); 
    <span style=color:#ff79c6>return</span> res; 
} 
</code></pre></div><h5 id=提前分配内存>提前分配内存</h5><p>在大循环中，如果每次迭代都需要动态分配内存，会频繁调用<code>realloc</code>函数，造成page-fault和cache miss，严重影响循环的执行效率。为了避免这种情况，我们可以在大循环开始前，提前统计并分配好足够的内存空间。不管是表达式计算中使用的向量，还是join/aggregate算子中使用的hash table，都可通过提前分配内存来减少频繁的内存分配和释放操作，从而提升性能。</p><p>如下所示，<code>vector</code>是个静态方法，用于对输入字符串向量执行trim操作。在for循环开始填充输出向量之前，首先对res_data和res_offsets进行预分配，确保它们有足够的内存空间来存储结果，避免了在循环中频繁调用<code>realloc</code>函数。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=color:#ff79c6>class</span> <span style=color:#50fa7b>FunctionTrim</span> <span style=color:#ff79c6>:</span> <span style=color:#ff79c6>public</span> IFunction 
{ 
<span style=color:#ff79c6>public</span><span style=color:#ff79c6>:</span> 
    <span style=color:#ff79c6>static</span> <span style=color:#8be9fd>void</span> vector( 
        <span style=color:#ff79c6>const</span> ColumnString<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>Chars <span style=color:#ff79c6>&amp;</span> input_data, 
        <span style=color:#ff79c6>const</span> ColumnString<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>Offsets <span style=color:#ff79c6>&amp;</span> input_offsets, 
        <span style=color:#ff79c6>const</span> std<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>optional<span style=color:#ff79c6>&lt;</span>SearchSymbols<span style=color:#ff79c6>&gt;</span> <span style=color:#ff79c6>&amp;</span> custom_trim_characters, 
        ColumnString<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>Chars <span style=color:#ff79c6>&amp;</span> res_data, 
        ColumnString<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>Offsets <span style=color:#ff79c6>&amp;</span> res_offsets, 
        size_t input_rows_count) 
    { 
        res_offsets.resize_exact(input_rows_count); 
        res_data.reserve_exact(input_data.size()); 
 
        size_t prev_offset <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>; 
        size_t res_offset <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>; 
 
        <span style=color:#ff79c6>const</span> UInt8 <span style=color:#ff79c6>*</span> start; 
        size_t length; 
 
        <span style=color:#ff79c6>for</span> (size_t i <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>; i <span style=color:#ff79c6>&lt;</span> input_rows_count; <span style=color:#ff79c6>+</span><span style=color:#ff79c6>+</span>i) 
        { 
            execute(<span style=color:#ff79c6>reinterpret_cast</span><span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>const</span> UInt8 <span style=color:#ff79c6>*</span><span style=color:#ff79c6>&gt;</span>(<span style=color:#ff79c6>&amp;</span>input_data[prev_offset]), input_offsets[i] <span style=color:#ff79c6>-</span> prev_offset <span style=color:#ff79c6>-</span> <span style=color:#bd93f9>1</span>, custom_trim_characters, start, length); 
 
            res_data.resize(res_data.size() <span style=color:#ff79c6>+</span> length <span style=color:#ff79c6>+</span> <span style=color:#bd93f9>1</span>); 
            memcpySmallAllowReadWriteOverflow15(<span style=color:#ff79c6>&amp;</span>res_data[res_offset], start, length); 
            res_offset <span style=color:#ff79c6>+</span><span style=color:#ff79c6>=</span> length <span style=color:#ff79c6>+</span> <span style=color:#bd93f9>1</span>; 
            res_data[res_offset <span style=color:#ff79c6>-</span> <span style=color:#bd93f9>1</span>] <span style=color:#ff79c6>=</span> <span style=color:#f1fa8c></span><span style=color:#f1fa8c>&#39;</span><span style=color:#f1fa8c>\0</span><span style=color:#f1fa8c>&#39;</span>; 
 
            res_offsets[i] <span style=color:#ff79c6>=</span> res_offset; 
            prev_offset <span style=color:#ff79c6>=</span> input_offsets[i]; 
        } 
    } 
}; 
</code></pre></div><p>选择合适的内存分配器并配置内存分配策略也能提升内存分配的效率，CH中默认使用jemalloc作为内存分配器。jemalloc是一个高性能的内存分配器，它通过多线程和分区策略来减少内存碎片和锁竞争，从而提高内存分配的效率。jemalloc可通过环境变量<code>JEMALLOC_CONF</code>进行配置，如设置分配器的线程数、分区大小、归还内存到OS的策略等。在CH中，默认的jemalloc配置是<code>percpu_arena:percpu,oversize_threshold:0,muzzy_decay_ms:0,dirty_decay_ms:5000,prof:true,prof_active:false,background_thread:true,lg_extent_max_active_fit:8</code>。在其他系统中可根据内存分配的特点和需求对<code>MALLOC_CONF</code>进行调整。</p><h5 id=memory-prefetch>Memory Prefetch</h5><p>Memory Prefetch是指在循环中提前加载下一次需要访问的数据到CPU缓存中，从而减少cache miss的概率，提高内存访问的性能。Memory Prefetch可以通过编译器内置的<code>__builtin_prefetch</code>函数来实现。在CH中，基于向量的计算一般是顺序访问，cache-miss概率较低，在此种场景中Memory Prefetch的效果并不明显。</p><p>但是在一些随机访问或非顺序访问的场景中，Memory Prefetch可以显著提高性能，最典型的例子就是CH中的aggregate算子，在聚合过程中，在处理当前行的group by key时，会提前获取固定步长后对应行的group by key，计算其哈希值，并根据哈希值找到hash table中对应bucket，使用<code>__builtin_prefetch</code>将bucket加载到CPU缓存中。这样下次处理被prefetch的行时，对应的bucket已经在CPU缓存中，避免了cache miss的开销。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp>            <span style=color:#6272a4>/// For all rows. 
</span><span style=color:#6272a4></span>            <span style=color:#ff79c6>for</span> (size_t i <span style=color:#ff79c6>=</span> row_begin; i <span style=color:#ff79c6>&lt;</span> row_end; <span style=color:#ff79c6>+</span><span style=color:#ff79c6>+</span>i) 
            { 
                <span style=color:#ff79c6>if</span> <span style=color:#50fa7b>constexpr</span> (prefetch <span style=color:#ff79c6>&amp;</span><span style=color:#ff79c6>&amp;</span> HasPrefetchMemberFunc<span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>decltype</span>(method.data), KeyHolder<span style=color:#ff79c6>&gt;</span>) 
                { 
                    <span style=color:#ff79c6>if</span> (i <span style=color:#ff79c6>=</span><span style=color:#ff79c6>=</span> row_begin <span style=color:#ff79c6>+</span> PrefetchingHelper<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>iterationsToMeasure()) 
                        prefetch_look_ahead <span style=color:#ff79c6>=</span> prefetching.calcPrefetchLookAhead(); 
 
                    <span style=color:#ff79c6>if</span> (i <span style=color:#ff79c6>+</span> prefetch_look_ahead <span style=color:#ff79c6>&lt;</span> row_end) 
                    { 
                        <span style=color:#ff79c6>auto</span> <span style=color:#ff79c6>&amp;</span><span style=color:#ff79c6>&amp;</span> key_holder <span style=color:#ff79c6>=</span> state.getKeyHolder(i <span style=color:#ff79c6>+</span> prefetch_look_ahead, <span style=color:#ff79c6>*</span>aggregates_pool); 
                        method.data.prefetch(std<span style=color:#ff79c6>:</span><span style=color:#ff79c6>:</span>move(key_holder)); 
                    } 
                } 
 
                state.emplaceKey(method.data, i, <span style=color:#ff79c6>*</span>aggregates_pool).setMapped(place); 
            } 
</code></pre></div><div class=highlight><pre style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp>    <span style=color:#ff79c6>template</span> <span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>typename</span> KeyHolder<span style=color:#ff79c6>&gt;</span> 
    <span style=color:#8be9fd>void</span> ALWAYS_INLINE prefetch(KeyHolder <span style=color:#ff79c6>&amp;</span><span style=color:#ff79c6>&amp;</span> key_holder) <span style=color:#ff79c6>const</span> 
    { 
        <span style=color:#ff79c6>const</span> <span style=color:#ff79c6>auto</span> <span style=color:#ff79c6>&amp;</span> key <span style=color:#ff79c6>=</span> keyHolderGetKey(key_holder); 
        <span style=color:#ff79c6>const</span> <span style=color:#ff79c6>auto</span> key_hash <span style=color:#ff79c6>=</span> hash(key); 
        prefetchByHash(key_hash); 
    } 
 
    <span style=color:#8be9fd>void</span> ALWAYS_INLINE <span style=color:#50fa7b>prefetchByHash</span>(size_t hash_key) <span style=color:#ff79c6>const</span> 
    { 
        <span style=color:#ff79c6>const</span> <span style=color:#ff79c6>auto</span> place <span style=color:#ff79c6>=</span> grower.place(hash_key); 
        __builtin_prefetch(<span style=color:#ff79c6>&amp;</span>buf[place]); 
    } 
</code></pre></div><h5 id=向量化优化>向量化优化</h5><p>以CH和Velox为代表的Native Engine，相比基于JVM的Vanilla Spark性能更快的重要原因就是，他们使用Native语言C++编写，能够充分利用CPU的SIMD指令集来进行向量化计算，SIMD指令集允许在单条指令中同时处理多个数据元素，从而大幅提升计算性能。向量化优化主要有两种方式</p><p><img src=https://backendhouse.github.io/images/Gluten%20+%20CH%20backend%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96--%E6%96%B9%E6%B3%95%E8%AE%BA/image-3.png alt="alt text"></p><ol><li>编译器自动向量化</li></ol><p>编译器自动向量化是指编译器在编译时自动将循环中的标量操作优化成SIMD指令。</p><p>以下是一个编译器自动向量化的例子，我们可以看到，循环中标量操作<code>c[i] = a[i] + b[i]</code>被clang编译器自动优化成了SIMD指令<code>paddd</code>，该指令操作128位XMM寄存器中的4个32位整数，等价于同时对4个整数进行加法操作。</p><p><img src=https://backendhouse.github.io/images/Gluten%20+%20CH%20backend%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96--%E6%96%B9%E6%B3%95%E8%AE%BA/image-2.png alt="alt text"></p><p>编译器会对满足条件的循环进行自动向量化优化。作为开发者，我们如何确定循环是否被编译器自动向量化了呢？有两种方法</p><ul><li><a href=https://backendhouse.github.io/post/cpu%E5%90%91%E9%87%8F%E5%8C%96%E8%AF%8A%E6%96%AD%E6%8A%80%E5%B7%A7/>添加编译器选项</a>，让clang或gcc在编译过程中输出向量化优化信息，循环代码是否被自动向量化了，如果没有，原因是什么。</li><li>使用工具(Compiler Explorer、gdb或Intel Vtune)查看编译器生成的汇编代码，检查循环中是否存在SIMD指令。这里推荐使用Intel Vtune，可视化功能做的比较好，方便查看源代码和对应的汇编码。</li></ul><p>CH和Gluten中有很多通过branchless编程移除循环中分支，从而使得编译器成功自动向量化的例子。如下：</p><p>优化前</p><div class=highlight><pre style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp>                <span style=color:#ff79c6>const</span> ColumnNullable <span style=color:#ff79c6>&amp;</span> condition_nullable <span style=color:#ff79c6>=</span> assert_cast<span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>const</span> ColumnNullable <span style=color:#ff79c6>&amp;</span><span style=color:#ff79c6>&gt;</span>(<span style=color:#ff79c6>*</span>instruction.condition); 
                <span style=color:#ff79c6>const</span> ColumnUInt8 <span style=color:#ff79c6>&amp;</span> condition_nested <span style=color:#ff79c6>=</span> assert_cast<span style=color:#ff79c6>&lt;</span><span style=color:#ff79c6>const</span> ColumnUInt8 <span style=color:#ff79c6>&amp;</span><span style=color:#ff79c6>&gt;</span>(condition_nullable.getNestedColumn()); 
                <span style=color:#ff79c6>const</span> <span style=color:#ff79c6>auto</span> <span style=color:#ff79c6>&amp;</span> condition_nested_data <span style=color:#ff79c6>=</span> condition_nested.getData(); 
                <span style=color:#ff79c6>const</span> NullMap <span style=color:#ff79c6>&amp;</span> condition_null_map <span style=color:#ff79c6>=</span> condition_nullable.getNullMapData(); 
 
                <span style=color:#ff79c6>for</span> (size_t row_i <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>; row_i <span style=color:#ff79c6>&lt;</span> rows; <span style=color:#ff79c6>+</span><span style=color:#ff79c6>+</span>row_i) 
                { 
                    <span style=color:#6272a4>/// Equivalent to below code. But it is able to utilize SIMD instructions. 
</span><span style=color:#6272a4></span>                    <span style=color:#6272a4>/// if (!condition_null_map[row_i] &amp;&amp; condition_nested_data[row_i]) 
</span><span style=color:#6272a4></span>                    <span style=color:#6272a4>///     inserts[row_i] = i; 
</span><span style=color:#6272a4></span>                    inserts[row_i] <span style=color:#ff79c6>+</span><span style=color:#ff79c6>=</span> (<span style=color:#ff79c6>~</span>condition_null_map[row_i] <span style=color:#ff79c6>&amp;</span> (<span style=color:#ff79c6>!</span><span style=color:#ff79c6>!</span>condition_nested_data[row_i])) <span style=color:#ff79c6>*</span> (i <span style=color:#ff79c6>-</span> inserts[row_i]); 
                } 
 
</code></pre></div><ol start=2><li>手动向量化</li></ol><p>手动向量化是指开发者在循环中显式使用SIMD指令来进行向量化计算。目前CH中是用<a href=https://www.intel.com/content/www/us/en/docs/intrinsics-guide>Intel Intrinsics</a>来编写x86上的SIMD指令，用<a href=https://developer.arm.com/documentation/den0018/a/NEON-Intrinsics/Using-NEON-intrinsics>NEON-intrinsics</a>编写ARM上的SIMD指令。手动向量化需要开发者对SIMD指令集有一定的了解。</p><p>C++最新标准也引入了SIMD的支持<code>std::experimental::simd</code>，它是一个可移植的SIMD编程接口，目前只是实验特性，期待早日成为C++26标准的一部分。</p><p>CH中的向量化实现了<a href=https://clickhouse.com/blog/cpu-dispatch-in-clickhouse>cpu dispatch</a>极致，有了它之后，用户无需在编译期决定使用哪种SIMD指令集，CH会在运行时根据CPU支持的指令级列表选择最优的SIMD指令集(SSE4.2、AVX2、AVX512等)来执行向量化计算。</p><p>以下是Gluten中实现spark floor函数的代码片段，它使用了avx2指令级来实现对Float32类型的向量化处理，一次迭代中可同时处理8个连续的Float32。其中<code>_mm256_loadu_ps</code>加载数据到AVX2寄存器，使用<code>_mm256_cmp_ps</code>进行比较操作，使用<code>_mm256_blendv_ps</code>进行条件选择，最后使用<code>_mm256_storeu_ps</code>将结果存储回内存。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp>    <span style=color:#8be9fd>void</span> <span style=color:#50fa7b>checkFloat32AndSetNullables</span>(Float32 <span style=color:#ff79c6>*</span> data, UInt8 <span style=color:#ff79c6>*</span> null_map, size_t size) { 
        <span style=color:#ff79c6>const</span> __m256 inf <span style=color:#ff79c6>=</span> _mm256_set1_ps(INFINITY); 
        <span style=color:#ff79c6>const</span> __m256 neg_inf <span style=color:#ff79c6>=</span> _mm256_set1_ps(<span style=color:#ff79c6>-</span>INFINITY); 
        <span style=color:#ff79c6>const</span> __m256 zero <span style=color:#ff79c6>=</span> _mm256_set1_ps(<span style=color:#bd93f9>0.0f</span>); 
 
        size_t i <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>; 
        <span style=color:#ff79c6>for</span> (; i <span style=color:#ff79c6>+</span> <span style=color:#bd93f9>7</span> <span style=color:#ff79c6>&lt;</span> size; i <span style=color:#ff79c6>+</span><span style=color:#ff79c6>=</span> <span style=color:#bd93f9>8</span>) 
        { 
            __m256 values <span style=color:#ff79c6>=</span> _mm256_loadu_ps(<span style=color:#ff79c6>&amp;</span>data[i]); 
 
            __m256 is_inf <span style=color:#ff79c6>=</span> _mm256_cmp_ps(values, inf, _CMP_EQ_OQ); 
            __m256 is_neg_inf <span style=color:#ff79c6>=</span> _mm256_cmp_ps(values, neg_inf, _CMP_EQ_OQ); 
            __m256 is_nan <span style=color:#ff79c6>=</span> _mm256_cmp_ps(values, values, _CMP_NEQ_UQ); 
            __m256 is_null <span style=color:#ff79c6>=</span> _mm256_or_ps(_mm256_or_ps(is_inf, is_neg_inf), is_nan); 
            __m256 new_values <span style=color:#ff79c6>=</span> _mm256_blendv_ps(values, zero, is_null); 
 
            _mm256_storeu_ps(<span style=color:#ff79c6>&amp;</span>data[i], new_values); 
 
            UInt32 mask <span style=color:#ff79c6>=</span> <span style=color:#ff79c6>static_cast</span><span style=color:#ff79c6>&lt;</span>UInt32<span style=color:#ff79c6>&gt;</span>(_mm256_movemask_ps(is_null)); 
            <span style=color:#ff79c6>for</span> (size_t j <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>; j <span style=color:#ff79c6>&lt;</span> <span style=color:#bd93f9>8</span>; <span style=color:#ff79c6>+</span><span style=color:#ff79c6>+</span>j) 
            { 
                UInt8 null_flag <span style=color:#ff79c6>=</span> (mask <span style=color:#ff79c6>&amp;</span> <span style=color:#bd93f9>1U</span>); 
                null_map[i <span style=color:#ff79c6>+</span> j] <span style=color:#ff79c6>=</span> null_flag; 
                mask <span style=color:#ff79c6>&gt;</span><span style=color:#ff79c6>&gt;</span><span style=color:#ff79c6>=</span> <span style=color:#bd93f9>1</span>; 
            } 
        } 
 
        <span style=color:#ff79c6>for</span> (; i <span style=color:#ff79c6>&lt;</span> size; <span style=color:#ff79c6>+</span><span style=color:#ff79c6>+</span>i) 
            checkAndSetNullable(data[i], null_map[i]); 
    } 
</code></pre></div><h5 id=代码生成>代码生成</h5><p>在OLAP数仓领域，代码生成一般和向量化优化相提并论。在论文<a href=https://www.vldb.org/pvldb/vol11/p2209-kersten.pdf>Everything You Always Wanted to Know About Compiled and Vectorized Queries But Were Afraid to Ask</a>中，作者比较了代码生成和向量化执行模型的性能。结果表明，代码生成在计算密集型查询方面表现更好， 因为它能够将数据保留在寄存器中，从而需要执行的指令更少。而向量化执行在隐藏并行cache-miss方面表现略好一些，因此在访问用于聚合或连接的大哈希表的内存受限查询中具有一定优势。在实际的工程实践中，可将二者结合使用。<a href=https://clickhouse.com/blog/clickhouse-just-in-time-compiler-jit>CH</a>便是一个很好的例子。</p><p>考虑这样的表达式<code>a / b + c / d + e / f + g / h + i / j</code>, 该表达式对应的DAG比较大，如果使用向量化执行模型，会生成大量的中间结果向量(如<code>a / b</code>的结果向量、<code>c / d</code>的结果向量)，并对它们进行读写，在此过程中产生了大量的page-fault和cache-miss，导致性能下降。而代码生成则会将整个表达式编译成一段机器码，直接在寄存器中计算结果，避免了中间结果写入/读出内存的开销。</p><p>代码生成的逻辑示意:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=color:#ff79c6>for</span> (size_t i <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>; i <span style=color:#ff79c6>&lt;</span> n; <span style=color:#ff79c6>+</span><span style=color:#ff79c6>+</span>i) 
{ 
    res[i] <span style=color:#ff79c6>=</span> a[i] <span style=color:#ff79c6>/</span> b[i] <span style=color:#ff79c6>+</span> c[i] <span style=color:#ff79c6>/</span> d[i] <span style=color:#ff79c6>+</span> e[i] <span style=color:#ff79c6>/</span> f[i] <span style=color:#ff79c6>+</span> g[i] <span style=color:#ff79c6>/</span> h[i] <span style=color:#ff79c6>+</span> i[i] <span style=color:#ff79c6>/</span> j[i]; 
} 
</code></pre></div><p>在CH中，代码生成是通过LLVM IR来实现的。CH中首先识别表达式中函数和参数类型是否支持JIT优化，如果支持，则将表达式转化成LLVM IR代码，然后使用LLVM将IR代码编译成机器码，缓存机器码到内存中。在执行阶段，CH会直接调用编译好的机器码来执行对应的表达式计算，而不是通过向量化模型解释执行。目前CH中支持int, float, double等基本类型的代码生成，支持的算子有project、filter、aggregate和sort。我们在Gluten + CH的优化中对JIT的功能进行了<a href=https://github.com/ClickHouse/ClickHouse/pull/73509>扩展</a>，支持了更多的表达式和基本类型，目前该功能正在贡献给CH社区。</p><h2 id=评估优化效果>评估优化效果</h2><p>优化完成后，评估优化效果是性能优化流程中至关重要的一环。只有通过科学、系统的评估，才能确认优化措施是否真正带来了预期的性能提升，避免“自嗨式优化”或因环境变化导致的误判。</p><p>评估过程建议分为开发环境和生产环境两个阶段，形成完整的闭环。</p><p>在开发环境中，首先要对优化前后的代码进行对比测试。此阶段的目标是快速、低成本地验证优化措施的有效性，并排除外部环境的干扰，可使用前面提到的Benchmark工具比对优化前后性能。开发环境评估的优势在于可控性强、调试方便，适合快速迭代和定位问题。但由于数据规模、并发压力等与生产环境存在差异，开发环境的评估结果仅作为初步参考。</p><p>开发环境验证通过后，优化措施需要在生产环境进行真实负载下的性能评估，生产环境更能体现性能优化的实际效果。</p><p>评估优化效果不是一次性的工作，而是一个持续的闭环过程。每次优化后，都要将评估结果与预期目标进行对比。如果效果未达预期，需要回到前面的分析和优化阶段，重新定位瓶颈、调整优化策略，直至达到目标。这个闭环过程确保了性能优化的科学性和有效性，避免了盲目优化和资源浪费。</p><h2 id=书籍推荐>书籍推荐</h2><ul><li>《Performance Analysis and Tuning on Modern CPUs》</li><li>《Optimizing Software in C++》</li><li>《性能之巅》</li><li>《BPF之巅》</li><li>《Extensible Query Optimizers in Practice》</li></ul><h2 id=参考>参考</h2><ul><li><a href=https://blog.csdn.net/zincooo/article/details/135245572>https://blog.csdn.net/zincooo/article/details/135245572</a></li><li><a href=https://en.algorithmica.org/hpc/>https://en.algorithmica.org/hpc/</a></li><li><a href=https://johnnysswlab.com/the-true-price-of-virtual-functions-in-c/>https://johnnysswlab.com/the-true-price-of-virtual-functions-in-c/</a></li></ul></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>后端侠</span></p><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>2025-05-28</span></p></div><footer class=post-footer><div class=post-tags><a href=/tags/gluten/>gluten</a>
<a href=/tags/clickhouse/>clickhouse</a>
<a href=/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/>性能优化</a></div><nav class=post-nav><a class=next href=/post/gluten+ch-backend%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-%E5%B7%A5%E5%85%B7%E7%AF%87/><span class="next-text nav-default">Gluten+CH backend性能优化--工具篇</span>
<span class="next-text nav-mobile">下一篇</span>
<i class="iconfont icon-right"></i></a></nav></footer></article></div><script src=https://utteranc.es/client.js repo=BackendHouse/hugo-comment issue-term=pathname theme=github-light crossorigin=anonymous async></script><noscript>Please enable JavaScript to view the <a href=https://github.com/utterance>comments powered by utterances.</a></noscript></div></main><footer id=footer class=footer><div class=social-links><a href=http://github.com/%e5%90%8e%e7%ab%af%e4%be%a0 class="iconfont icon-github" title=github></a><a href=https://backendhouse.github.io/index.xml type=application/rss+xml class="iconfont icon-rss" title=rss></a></div><div class=copyright><span class=power-by>由 <a class=hexo-link href=https://gohugo.io>Hugo</a> 强力驱动</span>
<span class=division>|</span>
<span class=theme-info>主题 -
<a class=theme-link href=https://github.com/olOwOlo/hugo-theme-even>Even</a></span>
<span class=copyright-year>&copy;
2020 -
2025<span class=heart><i class="iconfont icon-heart"></i></span><span>后端侠</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script src=https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin=anonymous></script><script type=text/javascript src=/js/main.min.c12618f9a600c40bd024996677e951e64d3487006775aeb22e200c990006c5c7.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-SYKLLYTW9K"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','G-SYKLLYTW9K');</script></body></html>